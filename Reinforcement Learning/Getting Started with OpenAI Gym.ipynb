{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing OpenAI Gym\n",
    "Making an environment, running some episodes and steps to try out and learn the way to use OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "84 -0.41174947] 1.0\n[ 0.01991774  0.14553249  0.06548485 -0.0967663 ] 1.0\n[ 0.02282839 -0.05046392  0.06354953  0.21583696] 1.0\n[ 0.02181912  0.14369468  0.06786626 -0.05614206] 1.0\n[ 0.02469301  0.33778122  0.06674342 -0.3266643 ] 1.0\n[ 0.03144863  0.14177564  0.06021014 -0.01370256] 1.0\n[ 0.03428415  0.33598473  0.05993609 -0.28679722] 1.0\n[ 0.04100384  0.53020299  0.05420014 -0.55999083] 1.0\n[ 0.0516079   0.724524    0.04300033 -0.83511727] 1.0\n[ 0.06609838  0.52884183  0.02629798 -0.52922713] 1.0\n[ 0.07667522  0.33335997  0.01571344 -0.22837503] 1.0\n[ 0.08334242  0.52825389  0.01114594 -0.51606025] 1.0\n[ 0.09390749  0.72321712  0.00082473 -0.8052101 ] 1.0\n[ 0.10837184  0.91832776 -0.01527947 -1.09763348] 1.0\n[ 0.12673839  1.11364751 -0.03723214 -1.3950709 ] 1.0\n[ 0.14901134  0.91900809 -0.06513356 -1.11425782] 1.0\n[ 0.1673915   1.11492194 -0.08741871 -1.42664119] 1.0\n[ 0.18968994  0.92098213 -0.11595154 -1.16251072] 1.0\n[ 0.20810958  0.72754514 -0.13920175 -0.908317  ] 1.0\n[ 0.22266049  0.53455404 -0.15736809 -0.66242381] 1.0\n[ 0.23335157  0.73147481 -0.17061657 -1.00023049] 1.0\n[ 0.24798106  0.92841529 -0.19062118 -1.34127018] 1.0\n[ 0.26654937  1.12535544 -0.21744658 -1.6870334 ] 1.0\nEpisode finished after 29 timesteps, got total reward of 30.0\n[ 0.04503    -0.17238551 -0.00434144  0.26673072] 1.0\n[ 0.04158229 -0.36744523  0.00099317  0.55804117] 1.0\n[ 0.03423338 -0.17233724  0.01215399  0.26567131] 1.0\n[ 0.03078664  0.02260916  0.01746742 -0.02315349] 1.0\n[ 0.03123882 -0.17275888  0.01700435  0.27498902] 1.0\n[ 0.02778364  0.02211638  0.02250413 -0.01228258] 1.0\n[ 0.02822597 -0.17332096  0.02225848  0.28741486] 1.0\n[0.02475955 0.02147661 0.02800678 0.00183434] 1.0\n[ 0.02518908 -0.17403557  0.02804346  0.30322052] 1.0\n[0.02170837 0.02067572 0.03410787 0.01951212] 1.0\n[ 0.02212188  0.21529235  0.03449812 -0.26221726] 1.0\n[ 0.02642773  0.40990531  0.02925377 -0.54382258] 1.0\n[ 0.03462584  0.60460421  0.01837732 -0.82714659] 1.0\n[ 0.04671792  0.79947011  0.00183439 -1.11399346] 1.0\n[ 0.06270732  0.99456793 -0.02044548 -1.40610039] 1.0\n[ 0.08259868  1.18993761 -0.04856749 -1.70510421] 1.0\n[ 0.10639744  1.38558355 -0.08266957 -2.0125003 ] 1.0\n[ 0.13410911  1.58146169 -0.12291958 -2.32959125] 1.0\n[ 0.16573834  1.77746401 -0.1695114  -2.65742386] 1.0\n[ 0.20128762  1.58396745 -0.22265988 -2.42093704] 1.0\nEpisode finished after 19 timesteps, got total reward of 20.0\n[ 0.04474511 -0.18249578 -0.02948795  0.33251339] 1.0\n[ 0.0410952  -0.37718588 -0.02283768  0.61575337] 1.0\n[ 0.03355148 -0.57198143 -0.01052262  0.90115681] 1.0\n[ 0.02211185 -0.76695924  0.00750052  1.19051374] 1.0\n[ 0.00677266 -0.96217758  0.03131079  1.48553815] 1.0\n[-0.01247089 -1.15766686  0.06102156  1.78783221] 1.0\n[-0.03562422 -1.35341834  0.0967782   2.09884213] 1.0\n[-0.06269259 -1.54937044  0.13875504  2.41980327] 1.0\n[-0.09368    -1.35569398  0.18715111  2.17274394] 1.0\n[-0.12079388 -1.16282542  0.23060599  1.94319462] 1.0\nEpisode finished after 9 timesteps, got total reward of 10.0\n[ 0.02160238  0.17163409 -0.00656287 -0.24570771] 1.0\n[ 0.02503506 -0.02339352 -0.01147703  0.04489792] 1.0\n[ 0.02456719 -0.21834903 -0.01057907  0.33393776] 1.0\n[ 0.02020021 -0.02307812 -0.00390031  0.0379376 ] 1.0\n[ 0.01973865 -0.21814392 -0.00314156  0.32938739] 1.0\n[ 0.01537577 -0.02297739  0.00344619  0.03571542] 1.0\n[ 0.01491622  0.17209497  0.00416049 -0.25587821] 1.0\n[ 0.01835812 -0.02308613 -0.00095707  0.03811409] 1.0\n[ 1.78963970e-02 -2.18194349e-01 -1.94787973e-04  3.30494901e-01] 1.0\n[ 0.01353251 -0.02306963  0.00641511  0.03775055] 1.0\n[ 0.01307112 -0.21828298  0.00717012  0.33245059] 1.0\n[ 0.00870546 -0.41350625  0.01381913  0.62738596] 1.0\n[ 4.35332961e-04 -6.08818326e-01  2.63668522e-02  9.24388802e-01] 1.0\n[-0.01174103 -0.80428632  0.04485463  1.22523984] 1.0\n[-0.02782676 -0.99995623  0.06935943  1.53163234] 1.0\n[-0.04782588 -0.80573545  0.09999207  1.26137697] 1.0\n[-0.06394059 -1.00198385  0.12521961  1.58362786] 1.0\n[-0.08398027 -0.80855421  0.15689217  1.33247359] 1.0\n[-0.10015135 -0.6157194   0.18354164  1.09271137] 1.0\n[-0.11246574 -0.81272211  0.20539587  1.43691077] 1.0\n[-0.12872018 -0.6206375   0.23413408  1.21480288] 1.0\nEpisode finished after 20 timesteps, got total reward of 21.0\n[ 0.04776415 -0.14673333 -0.02867579  0.33123739] 1.0\n[ 0.04482949  0.04878481 -0.02205104  0.02965121] 1.0\n[ 0.04580518 -0.14601408 -0.02145802  0.31529604] 1.0\n[ 0.0428849  -0.34082391 -0.0151521   0.60113533] 1.0\n[ 0.03606842 -0.53573066 -0.00312939  0.88900735] 1.0\n[ 0.02535381 -0.34056638  0.01465076  0.59534233] 1.0\n[ 0.01854248 -0.53589028  0.0265576   0.8926039 ] 1.0\n[ 0.00782468 -0.34113843  0.04440968  0.60838616] 1.0\n[ 0.00100191 -0.53685219  0.0565774   0.91471951] 1.0\n[-0.00973513 -0.73269183  0.07487179  1.22463382] 1.0\n[-0.02438897 -0.92869386  0.09936447  1.53980493] 1.0\n[-0.04296285 -0.73489765  0.13016057  1.2797096 ] 1.0\n[-0.0576608  -0.54165221  0.15575476  1.03045267] 1.0\n[-0.06849385 -0.34890675  0.17636381  0.79044129] 1.0\n[-0.07547198 -0.15658822  0.19217264  0.55802091] 1.0\n[-0.07860374 -0.35381441  0.20333306  0.90456591] 1.0\n[-0.08568003 -0.16194014  0.22142438  0.68205256] 1.0\nEpisode finished after 16 timesteps, got total reward of 17.0\n[ 0.0468543   0.24456583 -0.01391307 -0.34225432] 1.0\n[ 0.05174562  0.04964456 -0.02075815 -0.05399102] 1.0\n[ 0.05273851 -0.1451737  -0.02183797  0.23207094] 1.0\n[ 0.04983504  0.05025338 -0.01719656 -0.06741963] 1.0\n[ 0.0508401  -0.14461786 -0.01854495  0.21978847] 1.0\n[ 0.04794775 -0.33946988 -0.01414918  0.50656434] 1.0\n[ 0.04115835 -0.53438962 -0.00401789  0.79475497] 1.0\n[ 0.03047056 -0.33921276  0.01187721  0.50081078] 1.0\n[ 0.0236863  -0.14426023  0.02189342  0.21189443] 1.0\n[ 0.0208011  -0.33968826  0.02613131  0.51140237] 1.0\n[ 0.01400733 -0.14494396  0.03635936  0.22706738] 1.0\n[ 0.01110845  0.04964002  0.04090071 -0.05392838] 1.0\n[ 0.01210125 -0.1460438   0.03982214  0.25137332] 1.0\n[ 0.00918038  0.04848755  0.04484961 -0.02848774] 1.0\n[ 0.01015013 -0.14724793  0.04427985  0.27800159] 1.0\n[ 0.00720517 -0.34297269  0.04983988  0.58431498] 1.0\n[ 3.45715520e-04 -5.38756083e-01  6.15261824e-02  8.92272264e-01] 1.0\n[-0.01042941 -0.34452026  0.07937163  0.61954709] 1.0\n[-0.01731981 -0.54065582  0.09176257  0.93613498] 1.0\n[-0.02813293 -0.34688322  0.11048527  0.67363928] 1.0\n[-0.03507059 -0.54335324  0.12395805  0.99896404] 1.0\n[-0.04593766 -0.35008668  0.14393734  0.747639  ] 1.0\n[-0.05293939 -0.15721275  0.15889012  0.50349151] 1.0\n[-0.05608365  0.03535503  0.16895995  0.26479574] 1.0\n[-0.05537654 -0.16172493  0.17425586  0.60564433] 1.0\n[-0.05861104  0.03058728  0.18636875  0.37251696] 1.0\n[-0.0579993  -0.16662549  0.19381909  0.71768936] 1.0\n[-0.06133181  0.02536155  0.20817287  0.49172772] 1.0\n[-0.06082458 -0.17199483  0.21800743  0.84213268] 1.0\nEpisode finished after 28 timesteps, got total reward of 29.0\n[ 0.00579497  0.15525952 -0.03842161 -0.2950843 ] 1.0\n[ 0.00890016 -0.03929421 -0.0443233  -0.01476226] 1.0\n[ 0.00811428 -0.2337534  -0.04461854  0.26361328] 1.0\n[ 0.00343921 -0.42821103 -0.03934628  0.54189591] 1.0\n[-0.00512501 -0.62275852 -0.02850836  0.82192647] 1.0\n[-0.01758018 -0.81747905 -0.01206983  1.10550826] 1.0\n[-0.03392976 -0.62220049  0.01004034  0.80906331] 1.0\n[-0.04637377 -0.81745857  0.0262216   1.10488748] 1.0\n[-0.06272294 -1.01291535  0.04831935  1.40568013] 1.0\n[-0.08298125 -1.20860268  0.07643295  1.71306889] 1.0\n[-0.1071533  -1.40451433  0.11069433  2.02852781] 1.0\n[-0.13524359 -1.60059229  0.15126489  2.35332237] 1.0\n[-0.16725543 -1.40711405  0.19833134  2.11072139] 1.0\n[-0.19539771 -1.21445333  0.24054576  1.88532338] 1.0\nEpisode finished after 13 timesteps, got total reward of 14.0\n[-0.04785245 -0.18343423  0.01884099  0.25269407] 1.0\n[-0.05152114 -0.37882008  0.02389487  0.55125975] 1.0\n[-0.05909754 -0.57426934  0.03492007  0.85137437] 1.0\n[-0.07058293 -0.76984956  0.05194756  1.15483026] 1.0\n[-0.08597992 -0.96560899  0.07504416  1.46333902] 1.0\n[-0.1052921  -0.77148246  0.10431094  1.19501106] 1.0\n[-0.12072175 -0.57785419  0.12821116  0.93675917] 1.0\n[-0.13227883 -0.38467251  0.14694635  0.68695594] 1.0\n[-0.13997228 -0.58149553  0.16068546  1.02205557] 1.0\n[-0.15160219 -0.77835071  0.18112658  1.36057296] 1.0\n[-0.1671692  -0.58590155  0.20833804  1.12958205] 1.0\n[-0.17888723 -0.78305105  0.23092968  1.47972082] 1.0\nEpisode finished after 11 timesteps, got total reward of 12.0\n[ 0.04042985  0.23586146  0.00559227 -0.26147338] 1.0\n[ 4.51470815e-02  4.30903142e-01  3.62805210e-04 -5.52387201e-01] 1.0\n[ 0.05376514  0.2357761  -0.01068494 -0.25958999] 1.0\n[ 0.05848067  0.43104894 -0.01587674 -0.55562385] 1.0\n[ 0.06710165  0.23615346 -0.02698922 -0.26798503] 1.0\n[ 0.07182471  0.04142687 -0.03234892  0.01606461] 1.0\n[ 0.07265325  0.23699745 -0.03202762 -0.28664671] 1.0\n[ 0.0773932   0.43256117 -0.03776056 -0.58925636] 1.0\n[ 0.08604442  0.62819096 -0.04954569 -0.89359083] 1.0\n[ 0.09860824  0.82394859 -0.0674175  -1.20142742] 1.0\n[ 0.11508722  0.6297602  -0.09144605 -0.93061226] 1.0\n[ 0.12768242  0.82598943 -0.1100583  -1.25057394] 1.0\n[ 0.14420221  0.63243643 -0.13506977 -0.99429288] 1.0\n[ 0.15685094  0.82908121 -0.15495563 -1.32616336] 1.0\n[ 0.17343256  0.63621748 -0.1814789  -1.08570885] 1.0\n[ 0.18615691  0.83320824 -0.20319308 -1.42940489] 1.0\n[ 0.20282107  0.64109102 -0.23178117 -1.20648617] 1.0\nEpisode finished after 16 timesteps, got total reward of 17.0\n[ 0.01427071 -0.19664738  0.03697122  0.32412355] 1.0\n[ 0.01033776 -0.00207083  0.04345369  0.04332523] 1.0\n[ 0.01029634  0.19240195  0.0443202  -0.2353372 ] 1.0\n[ 0.01414438 -0.00332428  0.03961345  0.07098972] 1.0\n[ 0.0140779   0.19120802  0.04103325 -0.2089365 ] 1.0\n[ 0.01790206  0.38571995  0.03685452 -0.48839842] 1.0\n[ 0.02561646  0.58030308  0.02708655 -0.76924213] 1.0\n[ 0.03722252  0.77504194  0.01170171 -1.05328081] 1.0\n[ 0.05272336  0.57976681 -0.00936391 -0.75694794] 1.0\n[ 0.06431869  0.38477516 -0.02450287 -0.46722624] 1.0\n[ 0.0720142   0.58023457 -0.03384739 -0.76753047] 1.0\n[ 0.08361889  0.77580574 -0.049198   -1.07066842] 1.0\n[ 0.099135    0.97154248 -0.07061137 -1.37837667] 1.0\n[ 0.11856585  1.1674716  -0.09817891 -1.69228048] 1.0\n[ 0.14191528  1.36358081 -0.13202451 -2.01384595] 1.0\n[ 0.1691869   1.55980459 -0.17230143 -2.34432268] 1.0\n[ 0.20038299  1.36660135 -0.21918789 -2.10921536] 1.0\nEpisode finished after 16 timesteps, got total reward of 17.0\n[ 0.04774673  0.19504193  0.04279741 -0.22966352] 1.0\n[ 0.05164757  0.389527    0.03820414 -0.5085454 ] 1.0\n[ 0.05943811  0.58409045  0.02803323 -0.78894834] 1.0\n[ 0.07111992  0.38859493  0.01225427 -0.48757958] 1.0\n[ 0.07889182  0.58354186  0.00250268 -0.77637535] 1.0\n[ 0.09056265  0.7786293  -0.01302483 -1.06826981] 1.0\n[ 0.10613524  0.9739211  -0.03439023 -1.36501186] 1.0\n[ 0.12561366  1.16945645 -0.06169046 -1.66825019] 1.0\n[ 0.14900279  1.36523905 -0.09505547 -1.97949094] 1.0\n[ 0.17630757  1.56122402 -0.13464529 -2.30004552] 1.0\n[ 0.20753205  1.75730236 -0.1806462  -2.63096718] 1.0\n[ 0.2426781   1.95328285 -0.23326554 -2.97297596] 1.0\nEpisode finished after 11 timesteps, got total reward of 12.0\n[-0.0470035   0.15781323 -0.03223026 -0.30500764] 1.0\n[-0.04384724 -0.03683494 -0.03833041 -0.02266107] 1.0\n[-0.04458394  0.15881514 -0.03878363 -0.32718702] 1.0\n[-0.04140763 -0.0357338  -0.04532738 -0.04698258] 1.0\n[-0.04212231 -0.23017747 -0.04626703  0.23106166] 1.0\n[-0.04672586 -0.4246088  -0.04164579  0.50879891] 1.0\n[-0.05521804 -0.22892562 -0.03146982  0.20328831] 1.0\n[-0.05979655 -0.42358371 -0.02740405  0.48588028] 1.0\n[-0.06826822 -0.22808599 -0.01768644  0.18468802] 1.0\n[-0.07282994 -0.0327155  -0.01399268 -0.11352142] 1.0\n[-0.07348425  0.16260412 -0.01626311 -0.41058589] 1.0\n[-0.07023217  0.35795282 -0.02447483 -0.70835132] 1.0\n[-0.06307311  0.16317828 -0.03864186 -0.42347191] 1.0\n[-0.05980955  0.35882574 -0.04711129 -0.72808189] 1.0\n[-0.05263303  0.16438563 -0.06167293 -0.45059094] 1.0\n[-0.04934532  0.36032315 -0.07068475 -0.7620588 ] 1.0\n[-0.04213886  0.5563439  -0.08592593 -1.0761197 ] 1.0\n[-0.03101198  0.36245572 -0.10744832 -0.81159157] 1.0\n[-0.02376286  0.16895682 -0.12368015 -0.55454614] 1.0\n[-0.02038373 -0.02423129 -0.13477107 -0.30324685] 1.0\n[-0.02086835 -0.21720089 -0.14083601 -0.05592005] 1.0\n[-0.02521237 -0.02036996 -0.14195441 -0.38951225] 1.0\n[-0.02561977  0.17645139 -0.14974466 -0.72336921] 1.0\n[-0.02209074  0.37329222 -0.16421204 -1.05918683] 1.0\n[-0.0146249   0.18068091 -0.18539578 -0.82221819] 1.0\n[-0.01101128 -0.0114865  -0.20184014 -0.59310139] 1.0\n[-0.01124101  0.18580319 -0.21370217 -0.94196715] 1.0\nEpisode finished after 26 timesteps, got total reward of 27.0\n[-0.00475207 -0.17680827  0.03223244  0.27545533] 1.0\n[-0.00828823 -0.37237492  0.03774154  0.57812762] 1.0\n[-0.01573573 -0.56800494  0.04930409  0.88245706] 1.0\n[-0.02709583 -0.37358605  0.06695324  0.60567264] 1.0\n[-0.03456755 -0.17946107  0.07906669  0.33480714] 1.0\n[-0.03815677 -0.37561405  0.08576283  0.6513388 ] 1.0\n[-0.04566905 -0.57181916  0.09878961  0.96974813] 1.0\n[-0.05710543 -0.76811849  0.11818457  1.2917584 ] 1.0\n[-0.0724678  -0.96452789  0.14401974  1.6189828 ] 1.0\n[-0.09175836 -0.77136707  0.17639939  1.37443683] 1.0\n[-0.1071857  -0.57883321  0.20388813  1.14171055] 1.0\n[-0.11876237 -0.3868733   0.22672234  0.91926352]1.0\nEpisode finished after 11 timesteps, got total reward of 12.0\n[-0.04110998  0.18720359  0.01242873 -0.24258257] 1.0\n[-0.03736591  0.38214583  0.00757707 -0.53131939] 1.0\n[-0.02972299  0.18691812 -0.00304931 -0.2362586 ] 1.0\n[-0.02598463 -0.00816013 -0.00777449  0.05546093] 1.0\n[-0.02614783  0.18707242 -0.00666527 -0.23966474] 1.0\n[-0.02240638 -0.00795368 -0.01145856  0.05090835] 1.0\n[-0.02256545  0.18733068 -0.01044039 -0.24536771] 1.0\n[-0.01881884  0.38260019 -0.01534775 -0.54132542] 1.0\n[-0.01116684  0.57793446 -0.02617426 -0.83880438] 1.0\n[ 3.91851859e-04  3.83179507e-01 -4.29503451e-02 -5.54466371e-01] 1.0\n[ 0.00805544  0.18868613 -0.05403967 -0.27561887] 1.0\n[ 0.01182916  0.38453577 -0.05955205 -0.58484442] 1.0\n[ 0.01951988  0.58043913 -0.07124894 -0.89567649] 1.0\n[ 0.03112866  0.77645104 -0.08916247 -1.20987787] 1.0\n[ 0.04665768  0.97260398 -0.11336003 -1.52911754] 1.0\n[ 0.06610976  0.77901709 -0.14394238 -1.27385749] 1.0\n[ 0.0816901   0.97565184 -0.16941953 -1.60793234] 1.0\n[ 0.10120314  0.78288907 -0.20157817 -1.37249933] 1.0\n[ 0.11686092  0.97987851 -0.22902816 -1.72086392] 1.0\nEpisode finished after 18 timesteps, got total reward of 19.0\n[-0.02656655 -0.15187774 -0.03341871  0.31383103] 1.0\n[-0.0296041  -0.34650808 -0.02714209  0.59579027] 1.0\n[-0.03653426 -0.151017   -0.01522629  0.29468285] 1.0\n[-0.0395546   0.04431868 -0.00933263 -0.00276306] 1.0\n[-0.03866823 -0.15066819 -0.00938789  0.28696076] 1.0\n[-0.04168159  0.04458637 -0.00364868 -0.00866819] 1.0\n[-0.04078987  0.23976046 -0.00382204 -0.30250008] 1.0\n[-0.03599466  0.04469319 -0.00987204 -0.01102499] 1.0\n[-0.03510079 -0.1502858  -0.01009254  0.27852691] 1.0\n[-0.03810651  0.04497866 -0.004522   -0.01732202] 1.0\n[-0.03720693 -0.15007815 -0.00486845  0.27393074] 1.0\n[-0.0402085   0.04511293  0.00061017 -0.02028373] 1.0\n[-3.93062393e-02 -1.50017766e-01  2.04495109e-04  2.72591654e-01] 1.0\n[-0.04230659 -0.34514263  0.00565633  0.56533907] 1.0\n[-0.04920945 -0.54034348  0.01696311  0.85979861] 1.0\n[-0.06001632 -0.73569232  0.03415908  1.15776662] 1.0\n[-0.07473016 -0.54103183  0.05731441  0.87598704] 1.0\n[-0.0855508  -0.73688404  0.07483416  1.18612419] 1.0\n[-0.10028848 -0.93289244  0.09855664  1.50129462] 1.0\n[-0.11894633 -1.12906336  0.12858253  1.82305181] 1.0\n[-0.1415276  -0.93558221  0.16504357  1.57292515] 1.0\n[-0.16023924 -1.13224339  0.19650207  1.91221115] 1.0\n[-0.18288411 -0.9397081   0.23474629  1.68636662] 1.0\nEpisode finished after 22 timesteps, got total reward of 23.0\n[ 0.02355097 -0.15872561  0.011365    0.29213681] 1.0\n[0.02037646 0.03623247 0.01720774 0.00305982] 1.0\n[ 0.02110111 -0.15913198  0.01726893  0.30112194] 1.0\n[ 0.01791847 -0.35449576  0.02329137  0.59920072] 1.0\n[ 0.01082855 -0.54993571  0.03527539  0.89912817] 1.0\n[-1.70163449e-04 -3.55309134e-01  5.32579508e-02  6.17738745e-01] 1.0\n[-0.00727635 -0.16097001  0.06561273  0.34229382] 1.0\n[-0.01049575 -0.35696111  0.0724586   0.65492418] 1.0\n[-0.01763497 -0.55301311  0.08555709  0.96951472] 1.0\n[-0.02869523 -0.74917292  0.10494738  1.28780129] 1.0\n[-0.04367869 -0.94546184  0.13070341  1.61141264] 1.0\n[-0.06258793 -1.14186272  0.16293166  1.94181863] 1.0\n[-0.08542518 -1.33830527  0.20176803  2.28027017] 1.0\n[-0.11219129 -1.5346494   0.24737343  2.62772987] 1.0\nEpisode finished after 13 timesteps, got total reward of 14.0\n[ 0.02032485  0.14991477  0.01627353 -0.31063523] 1.0\n[ 0.02332315  0.34480113  0.01006083 -0.59814186] 1.0\n[ 0.03021917  0.14953986 -0.00190201 -0.30230694] 1.0\n[ 0.03320997 -0.04555493 -0.00794815 -0.01022447] 1.0\n[ 0.03229887 -0.240562   -0.00815264  0.27994016] 1.0\n[ 0.02748763 -0.43556671 -0.00255383  0.57004065] 1.0\n[ 0.01877629 -0.24040903  0.00884698  0.27655427] 1.0\n[ 0.01396811 -0.04541441  0.01437806 -0.01332524] 1.0\n[ 0.01305982 -0.24073958  0.01411156  0.28385924] 1.0\n[ 0.00824503 -0.43605993  0.01978874  0.58095925] 1.0\n[-4.76166487e-04 -6.31453491e-01  3.14079288e-02  8.79809721e-01] 1.0\n[-0.01310524 -0.82698776  0.04900412  1.18219888] 1.0\n[-0.02964499 -1.02271022  0.0726481   1.48983159] 1.0\n[-0.0500992  -1.21863768  0.10244473  1.80428734] 1.0\n[-0.07447195 -1.02479821  0.13853048  1.54511864] 1.0\n[-0.09496791 -1.2212858   0.16943285  1.87762431] 1.0\n[-0.11939363 -1.02836891  0.20698534  1.64196794] 1.0\n[-0.13996101 -0.83618473  0.2398247   1.42026505] 1.0\nEpisode finished after 17 timesteps, got total reward of 18.0\n[ 0.0147286   0.23037054 -0.04337294 -0.33958126] 1.0\n[ 0.01933601  0.03589171 -0.05016456 -0.06088502] 1.0\n[ 0.02005384  0.23169569 -0.05138226 -0.3689637 ] 1.0\n[ 0.02468776  0.42750862 -0.05876154 -0.6773952 ] 1.0\n[ 0.03323793  0.62339564 -0.07230944 -0.98798453] 1.0\n[ 0.04570584  0.42931242 -0.09206913 -0.71886093] 1.0\n[ 0.05429209  0.62557959 -0.10644635 -1.03904488] 1.0\n[ 0.06680368  0.82194254 -0.12722725 -1.36315832] 1.0\n[ 0.08324253  0.62862329 -0.15449041 -1.11282718] 1.0\n[ 0.095815    0.82539894 -0.17674696 -1.44971501] 1.0\n[ 0.11232298  0.63283442 -0.20574126 -1.21706168] 1.0\n[ 0.12497966  0.82992733 -0.23008249 -1.56652805] 1.0\nEpisode finished after 11 timesteps, got total reward of 12.0\n[ 0.00653496  0.22039935  0.0442993  -0.31055975] 1.0\n[ 0.01094294  0.02467517  0.0380881  -0.00424176] 1.0\n[ 0.01143645 -0.17097173  0.03800327  0.30021095] 1.0\n[0.00801701 0.02358851 0.04400749 0.01975157] 1.0\n[ 0.00848878 -0.17213603  0.04440252  0.32598815] 1.0\n[ 0.00504606 -0.36786112  0.05092228  0.63233648] 1.0\n[-0.00231116 -0.1734852   0.06356901  0.35611522] 1.0\n[-0.00578087 -0.36945064  0.07069131  0.66814636] 1.0\n[-0.01316988 -0.56548071  0.08405424  0.98222301] 1.0\n[-0.02447949 -0.76162227  0.1036987   1.3000795 ] 1.0\n[-0.03971194 -0.95789621  0.12970029  1.62334166] 1.0\n[-0.05886986 -0.76451773  0.16216713  1.37373538] 1.0\n[-0.07416022 -0.96125231  0.18964183  1.71243386] 1.0\n[-0.09338526 -1.15797845  0.22389051  2.05765376] 1.0\nEpisode finished after 13 timesteps, got total reward of 14.0\n[-0.0417841   0.1550642  -0.00843463 -0.33196363] 1.0\n[-0.03868282 -0.03993669 -0.01507391 -0.04195246] 1.0\n[-0.03948155 -0.23483927 -0.01591296  0.24593665] 1.0\n[-0.04417834 -0.42973038 -0.01099422  0.53355808] 1.0\n[-0.05277294 -0.23445555 -0.00032306  0.2374313 ] 1.0\n[-0.05746205 -0.42957288  0.00442556  0.5300123 ] 1.0\n[-0.06605351 -0.62475681  0.01502581  0.82408644] 1.0\n[-0.07854865 -0.82008104  0.03150754  1.12145713] 1.0\n[-0.09495027 -0.62538613  0.05393668  0.83882141] 1.0\n[-0.10745799 -0.82120147  0.07071311  1.14796697] 1.0\n[-0.12388202 -1.01717175  0.09367245  1.46196009] 1.0\n[-0.14422546 -1.21330866  0.12291165  1.78237508] 1.0\n[-0.16849163 -1.40957978  0.15855915  2.11060583] 1.0\n[-0.19668322 -1.60589345  0.20077127  2.44780374] 1.0\n[-0.22880109 -1.41296975  0.24972734  2.22286206] 1.0\nEpisode finished after 14 timesteps, got total reward of 15.0\n"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "cum_reward = 0\n",
    "\n",
    "# Running for 20 episodes\n",
    "for i_eps in range(20):\n",
    "    observation = env.reset()\n",
    "    last_reward = 0\n",
    "\n",
    "    # For each episode run 100 timesteps\n",
    "    for timesteps in range(100):\n",
    "        env.render()\n",
    "\n",
    "        # Random action done for each timesteps\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        print(observation, reward)\n",
    "        cum_reward += reward\n",
    "        if done:\n",
    "            print(f'Episode finished after {timesteps} timesteps, got total reward of {cum_reward}')\n",
    "\n",
    "            last_reward = cum_reward\n",
    "            cum_reward = 0\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}